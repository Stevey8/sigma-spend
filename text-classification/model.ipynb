{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Python built-in RNG\n",
    "random.seed(SEED)\n",
    "\n",
    "# Numpy RNG\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch RNG\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Ensure deterministic operations in PyTorch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entertainment' 'grocery' 'health & wellness' 'restaurant' 'shopping'\n",
      " 'transportation']\n"
     ]
    }
   ],
   "source": [
    "# finetuning for ambiguous terms  \n",
    "ambiguous_terms = pd.read_csv(\"data/ambiguous_terms.csv\", header=0) \n",
    "X_text = ambiguous_terms['name'].tolist()\n",
    "y = ambiguous_terms['category'].tolist()\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [InputExample(texts=[text,\"\"], label=label) for text, label in zip(X_text, y_encoded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=model,\n",
    "    sentence_embedding_dimension=model.get_sentence_embedding_dimension(),\n",
    "    num_labels=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21d50d594a47008675f96a5b0b4127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9d3ff1f24e4854bceba62a0aac15a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459d199189e84f558aba12b1bc2ec147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0d130dbd4d48448346fd0d35e2bdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=3,\n",
    "    warmup_steps=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bills' 'entertainment' 'grocery' 'health & wellness' 'restaurant'\n",
      " 'shopping' 'transportation']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/name_price.csv\", header=0) \n",
    "# df.head()\n",
    "df_X = df['name'].tolist()\n",
    "df_y = df['category'].tolist()\n",
    "df_le = LabelEncoder()\n",
    "df_X_embedded = model.encode(df_X, convert_to_numpy=True)  # Embeddings from finetuned SBERT\n",
    "df_y_encoded = df_le.fit_transform(df_y)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)\n",
    "clf.fit(df_X_embedded, df_y_encoded)\n",
    "print(df_le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_pred(name): \n",
    "    embedding = model.encode([name])\n",
    "    proba = clf.predict_proba(embedding)[0]\n",
    "    \n",
    "    # Get top 3 indices sorted by probability (descending)\n",
    "    top3_idx = np.argsort(proba)[-3:][::-1]\n",
    "    top_class = df_le.classes_[top3_idx[0]]\n",
    "    top_proba = proba[top3_idx[0]]\n",
    "\n",
    "    # Get runner-up classes (2nd and 3rd highest)\n",
    "    runner_ups = [(df_le.classes_[i], proba[i]) for i in top3_idx[1:]]\n",
    "\n",
    "    # Format result\n",
    "    result = f\"→ Predicted category: {top_class} ({top_proba:.2f})\"\n",
    "    if runner_ups:\n",
    "        others_formatted = \", \".join([f\"{cls} ({p:.2f})\" for cls, p in runner_ups])\n",
    "        result += f\" | Other possible classes: {others_formatted}\"\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Predicted category: restaurant (0.26) | Other possible classes: shopping (0.22), grocery (0.20)\n"
     ]
    }
   ],
   "source": [
    "# try it out! \n",
    "# print(soft_pred(\"trattoria taverniti\"))\n",
    "# print(soft_pred(\"foam roller\"))\n",
    "# print(soft_pred(\"supermarket\"))\n",
    "print(soft_pred(\"uniqlo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_pred_testing(name, margin=0.7): \n",
    "    embedding = model.encode([name])\n",
    "    proba = clf.predict_proba(embedding)[0]\n",
    "    \n",
    "    # Get top two indices and their probabilities\n",
    "    top2_idx = np.argsort(proba)[-2:][::-1]\n",
    "    p1, p2 = proba[top2_idx[0]], proba[top2_idx[1]]\n",
    "    c1, c2 = df_le.classes_[top2_idx[0]], df_le.classes_[top2_idx[1]]\n",
    "    \n",
    "    if p1 - p2 >= margin:\n",
    "        return f\"→ Predicted category: {c1} ({p1:.2f})\"\n",
    "    else:\n",
    "        return f\"→ Ambiguous. Top 2: {c1} ({p1:.2f}), {c2} ({p2:.2f})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Ambiguous. Top 2: restaurant (0.36), grocery (0.15)\n",
      "→ Ambiguous. Top 2: grocery (0.48), restaurant (0.28)\n",
      "→ Ambiguous. Top 2: health & wellness (0.28), entertainment (0.23)\n",
      "→ Ambiguous. Top 2: health & wellness (0.47), entertainment (0.14)\n",
      "→ Ambiguous. Top 2: health & wellness (0.40), grocery (0.14)\n",
      "→ Ambiguous. Top 2: health & wellness (0.56), shopping (0.10)\n",
      "→ Ambiguous. Top 2: transportation (0.73), grocery (0.06)\n",
      "→ Ambiguous. Top 2: transportation (0.34), restaurant (0.26)\n",
      "→ Ambiguous. Top 2: transportation (0.57), restaurant (0.17)\n",
      "→ Ambiguous. Top 2: transportation (0.41), grocery (0.36)\n"
     ]
    }
   ],
   "source": [
    "print(soft_pred_testing(\"osteria giulia\"))\n",
    "print(soft_pred_testing(\"freshway foodmart\"))\n",
    "print(soft_pred_testing(\"basketball\"))\n",
    "print(soft_pred_testing(\"basketball drop in\"))\n",
    "print(soft_pred_testing(\"physio\"))\n",
    "print(soft_pred_testing(\"physiology\"))\n",
    "print(soft_pred_testing(\"uber\"))\n",
    "print(soft_pred_testing(\"uber eats\"))\n",
    "print(soft_pred_testing(\"Subway\"))\n",
    "print(soft_pred_testing(\"metro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ predictions: grocery (0.48), restaurant (0.28), transportation (0.09), shopping (0.06), entertainment (0.04), health & wellness (0.03), bills (0.02)\n",
      "→ predictions: shopping (0.25), restaurant (0.22), grocery (0.18), transportation (0.13), health & wellness (0.10), entertainment (0.07), bills (0.04)\n",
      "→ predictions: restaurant (0.37), entertainment (0.25), grocery (0.14), health & wellness (0.08), shopping (0.07), transportation (0.05), bills (0.04)\n"
     ]
    }
   ],
   "source": [
    "def print_all_probs(name):\n",
    "    embedding = model.encode([name])\n",
    "    proba = clf.predict_proba(embedding)[0]\n",
    "    \n",
    "    # top5_idx = np.argsort(proba)[-5:][::-1]\n",
    "    \n",
    "    result = [f\"{df_le.classes_[i]} ({proba[i]:.2f})\" for i in np.argsort(proba)[::-1]]\n",
    "    return \"→ predictions: \" + \", \".join(result)\n",
    "\n",
    "print(print_all_probs(\"freshway foodmart\"))\n",
    "print(print_all_probs(\"shell\"))\n",
    "print(print_all_probs(\"casa loma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. register model\n",
    "# 2. fine tune model even more (now only have the ambiguous terms file; maybe there are more ways to fine tune it)\n",
    "# 2. create a new file for bayesian updating (using dirichlet prior); likelihood will be the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood:\n",
      "['bills (0.04)', 'entertainment (0.25)', 'grocery (0.14)', 'health & wellness (0.08)', 'restaurant (0.37)', 'shopping (0.07)', 'transportation (0.05)']\n",
      "prior:\n",
      "[0.097 0.419 0.097 0.097 0.097 0.097 0.097]\n",
      "posterior:\n",
      "['bills (0.02)', 'entertainment (0.59)', 'grocery (0.08)', 'health & wellness (0.05)', 'restaurant (0.20)', 'shopping (0.04)', 'transportation (0.02)']\n"
     ]
    }
   ],
   "source": [
    "# try updating with dirichlet prior\n",
    "\n",
    "casaloma = model.encode([\"casa loma\"])\n",
    "proba_casaloma = clf.predict_proba(casaloma)[0]\n",
    "result = [f\"{df_le.classes_[i]} ({proba_casaloma[i]:.2f})\" for i in range(len(proba_casaloma))]\n",
    "print('likelihood:')\n",
    "print(f'{result}')\n",
    "\n",
    "# prior_casaloma = np.array([0.1,1.1,0.1,0.1,0.1,0.1,0.1])\n",
    "# prior_casaloma = np.array([0.5,1.5,0.5,0.5,0.5,0.5,0.5])\n",
    "prior_casaloma = np.array([0.3,1.3,0.3,0.3,0.3,0.3,0.3])\n",
    "prior_casaloma = prior_casaloma / np.sum(prior_casaloma)\n",
    "print('prior:')\n",
    "print(f'{np.round(prior_casaloma,3)}')\n",
    "\n",
    "posterior_casaloma = (prior_casaloma * proba_casaloma) / np.sum(prior_casaloma * proba_casaloma)\n",
    "print('posterior:')\n",
    "print([f\"{df_le.classes_[i]} ({posterior_casaloma[i]:.2f})\" for i in range(len(posterior_casaloma))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood:\n",
      "['bills (0.013)', 'entertainment (0.053)', 'grocery (0.126)', 'health & wellness (0.024)', 'restaurant (0.166)', 'shopping (0.045)', 'transportation (0.573)']\n",
      "prior:\n",
      "[0.059 0.059 0.059 0.059 0.059 0.059 0.647]\n",
      "posterior:\n",
      "['bills (0.002)', 'entertainment (0.008)', 'grocery (0.019)', 'health & wellness (0.004)', 'restaurant (0.025)', 'shopping (0.007)', 'transportation (0.937)']\n",
      "\n",
      "second iteration\n",
      "prior:\n",
      "[0.037 0.037 0.037 0.037 0.407 0.037 0.407]\n",
      "posterior:\n",
      "['bills (0.002)', 'entertainment (0.006)', 'grocery (0.015)', 'health & wellness (0.003)', 'restaurant (0.217)', 'shopping (0.005)', 'transportation (0.752)']\n"
     ]
    }
   ],
   "source": [
    "# try the case: subway\n",
    "\n",
    "subway = model.encode([\"subway\"])\n",
    "proba_subway = clf.predict_proba(subway)[0]\n",
    "result = [f\"{df_le.classes_[i]} ({proba_subway[i]:.3f})\" for i in range(len(proba_subway))]\n",
    "print('likelihood:')\n",
    "print(f'{result}')\n",
    "\n",
    "prior_subway = np.array([0.1,0.1,0.1,0.1,0.1,0.1,1.1])\n",
    "# prior_subway = np.array([0.5,0.5,0.5,0.5,0.5,0.5,1.5])\n",
    "# prior_subway = np.array([0.3,0.3,0.3,0.3,0.3,0.3,1.3])\n",
    "prior_subway = prior_subway / np.sum(prior_subway)\n",
    "print('prior:') \n",
    "print(f'{np.round(prior_subway, 3)}')\n",
    "\n",
    "posterior_subway = (prior_subway * proba_subway) / np.sum(prior_subway * proba_subway)\n",
    "print('posterior:')\n",
    "print([f\"{df_le.classes_[i]} ({posterior_subway[i]:.3f})\" for i in range(len(posterior_subway))])\n",
    "\n",
    "\n",
    "# second iteration\n",
    "print(\"\")\n",
    "print('second iteration')\n",
    "\n",
    "prior_subway = np.array([0.1,0.1,0.1,0.1,1.1,0.1,1.1])\n",
    "# prior_subway = np.array([0.3,0.3,0.3,0.3,1.3,0.3,1.3])\n",
    "prior_subway = prior_subway / np.sum(prior_subway)\n",
    "print('prior:') \n",
    "print(f'{np.round(prior_subway, 3)}')\n",
    "\n",
    "posterior_subway = (prior_subway * proba_subway) / np.sum(prior_subway * proba_subway)\n",
    "print('posterior:')\n",
    "print([f\"{df_le.classes_[i]} ({posterior_subway[i]:.3f})\" for i in range(len(posterior_subway))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
